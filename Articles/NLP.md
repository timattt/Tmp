# Эмбединги

## Без нейросетей

* смысл слова определеяется контекстом
* идем окном
* строим матрицу встречаемости слов, iое слово с jым
* можно понизить размерность
* еще можно сингулярно разложить. Тогда строки первой матрицы и строки последней - искомые эмбединги

## С нейросетями

* обучаем нейросеть - на вход onehot слово - на выходе тоже onehot слово. Фактически это задача классификации 

![image](https://github.com/timattt/Tmp/assets/25401699/3ed4276a-1107-4b4f-bcac-839f275cdd8d)

# seq2seq

## Encoder-decoder

![image](https://github.com/timattt/Tmp/assets/25401699/a1f2a5fc-8fbe-438a-8713-65aad2eedeff)


# attention

